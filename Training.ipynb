{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ac9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam, AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from opendelta import AdapterModel\n",
    "\n",
    "seed=514\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddc1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 20\n",
    "path = 'emilyalsentzer/Bio_ClinicalBERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c735cb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained(path)\n",
    "classifier = AutoModelForSequenceClassification.from_pretrained(path, num_labels=2)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "classifier = classifier.to(device)\n",
    "delta = AdapterModel(classifier, bottleneck_dim=16 if \"base\" in path else 32)\n",
    "delta.freeze_module(classifier, exclude=[\"adapter\", \"pooler\", \"classifier\"])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam([p for p in classifier.parameters()], lr=1e-5, eps=1e-6, betas=(0.9, 0.999))\n",
    "scheduler = ExponentialLR(optimizer, .67**(1/5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ec5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, batch_size = 8):\n",
    "\n",
    "    bar = tqdm(range(0, len(dataset), batch_size))\n",
    "    \n",
    "    accuracy = torch.BoolTensor([]).to(device)\n",
    "\n",
    "    for idx in bar:\n",
    "        dataset_batch = dataset[idx:idx+batch_size]\n",
    "        premises = [data[\"premise\"] for data in dataset_batch]\n",
    "        hypotheses = [data[\"hypothesis\"] for data in dataset_batch]\n",
    "        labels = [data[\"label\"] for data in dataset_batch]\n",
    "\n",
    "        inputs = tok(hypotheses, premises, padding=True, return_tensors='pt')\n",
    "        \n",
    "        for key in inputs.keys():\n",
    "            inputs[key] = inputs[key][:, :512].to(device)\n",
    "        scores = classifier(**inputs)[-1]\n",
    "        labels = torch.LongTensor(labels).to(device)\n",
    "\n",
    "        classifier.zero_grad()\n",
    "\n",
    "        loss = criterion(scores, labels)\n",
    "        \n",
    "        predictions = scores.argmax(-1)\n",
    "        \n",
    "        accuracy = torch.cat((accuracy, predictions == labels), 0)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        bar.set_description(f'@Train #Loss={loss:.4} #Accuracy={accuracy.float().mean():.4}')\n",
    "        \n",
    "def evaluate(dataset, batch_size = 8):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        bar = tqdm(range(0, len(dataset), batch_size))\n",
    "\n",
    "        accuracy = torch.BoolTensor([]).to(device)\n",
    "\n",
    "        for idx in bar:\n",
    "            dataset_batch = dataset[idx:idx+batch_size]\n",
    "            premises = [data[\"premise\"] for data in dataset_batch]\n",
    "            hypotheses = [data[\"hypothesis\"] for data in dataset_batch]\n",
    "            labels = [data[\"label\"] for data in dataset_batch]\n",
    "\n",
    "            inputs = tok(premises, hypotheses, padding=True, return_tensors='pt')\n",
    "\n",
    "            for key in inputs.keys():\n",
    "                inputs[key] = inputs[key][:, :512].to(device)\n",
    "            scores = classifier(**inputs)[-1]\n",
    "            labels = torch.LongTensor(labels).to(device)\n",
    "\n",
    "            loss = criterion(scores, labels)\n",
    "\n",
    "            predictions = scores.argmax(-1)\n",
    "\n",
    "            accuracy = torch.cat((accuracy, predictions == labels), 0)\n",
    "\n",
    "            bar.set_description(f'@Evaluate #Loss={loss:.4} #Accuracy={accuracy.float().mean():.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cf8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(fname):\n",
    "    \n",
    "    labels = ['Contradiction', 'Entailment']\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    items = json.load(open(fname))\n",
    "\n",
    "    for key in items.keys():\n",
    "        item = items[key]\n",
    "        if item['Type'] == \"Single\":\n",
    "            section = item['Section_id']\n",
    "            primary = item['Primary_id']\n",
    "            ids = item['Primary_evidence_index']\n",
    "            lines = json.load(open(f\"data/CT/{primary}.json\"))[section]\n",
    "            premise = f\"{section}: \" + \" \".join([lines[idx].strip() for idx in ids])\n",
    "            hypothesis = item['Statement']\n",
    "            label = item['Label']\n",
    "\n",
    "            data = {\n",
    "                \"premise\":premise,\n",
    "                \"hypothesis\":hypothesis,\n",
    "                \"label\":labels.index(label),\n",
    "            }\n",
    "\n",
    "            dataset.append(data)\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1aa211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(\"data/train.json\")\n",
    "dataset_dev = load_dataset(\"data/dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543d2724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22db0a1e4395417d8d5370ff9395b5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5ed805444749b19eadfea5f6a370a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39974176e53b45488f1ffbc5acd29702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87dc638343e4598ad5cab2f4d9e9cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29a1f8bff444355898128fb0f92d74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac05fded79c34493a729aa2b738d82b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e54d1afe8144a9b83e76a759062a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af77ed53f87d40d0b2b44147de4b4ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dc494a649e40f78467b0ebfaaddda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fa4bc2534f442296a6015a8349fd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377e4bebed8a48e4bb051a39b889b48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040d802d4ef84500a22bfc25bb06443a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff604b605b794423b8db93fb1da8f6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025f1145cc084eeaaea47180694f621c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1b92b81e014893a1622e19f873b6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373a2c8dd16b4efc9d892df86b4cb065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce76af2a0e84bba80a7f4aab56857e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e4d98ef3c84faf885df6d29990fdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dce9bb000e045d19d0275f2e51e6d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa9d792432e4492b6dcfdc856e01c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(max_epoch):\n",
    "    train(dataset_train)\n",
    "    evaluate(dataset_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb3ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "komeiji",
   "language": "python",
   "name": "komeiji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
